{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9b8d42",
   "metadata": {},
   "source": [
    "## FastApi  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastapi uvicorn\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Simple endpoint\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Welcome to GenAI API!\"}\n",
    "\n",
    "# Endpoint with parameters\n",
    "@app.get(\"/generate/{prompt}\")\n",
    "def generate_text(prompt: str, max_tokens: int = 100):\n",
    "    # In real app: call LLM here\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"response\": f\"Generated text for: {prompt}\"\n",
    "    }\n",
    "\n",
    "# Run: uvicorn filename:app --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bd8a7",
   "metadata": {},
   "source": [
    "## FastApi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a802d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Define data structure\n",
    "class PromptRequest(BaseModel):\n",
    "    prompt: str\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 150\n",
    "\n",
    "# POST endpoint\n",
    "@app.post(\"/chat\")\n",
    "def chat_completion(request: PromptRequest):\n",
    "    # Process the prompt\n",
    "    response = {\n",
    "        \"prompt\": request.prompt,\n",
    "        \"settings\": {\n",
    "            \"temperature\": request.temperature,\n",
    "            \"max_tokens\": request.max_tokens\n",
    "        },\n",
    "        \"completion\": \"This is where LLM response goes\"\n",
    "    }\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb5899",
   "metadata": {},
   "source": [
    "## FastApi 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d21a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load prompt templates\n",
    "def load_templates():\n",
    "    df = pd.read_csv('prompt_templates.csv')\n",
    "    return df\n",
    "\n",
    "# Calculate similarity (NumPy)\n",
    "def find_best_template(query_embedding, template_embeddings):\n",
    "    similarities = np.array([\n",
    "        np.dot(query_embedding, t) / (np.linalg.norm(query_embedding) * np.linalg.norm(t))\n",
    "        for t in template_embeddings\n",
    "    ])\n",
    "    return np.argmax(similarities)\n",
    "\n",
    "# API endpoint\n",
    "@app.post(\"/find-template\")\n",
    "def get_template(query: str):\n",
    "    # This is a simplified example showing integration\n",
    "    templates = load_templates()\n",
    "    return {\"best_template\": templates.iloc[0]['template']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d6731",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
